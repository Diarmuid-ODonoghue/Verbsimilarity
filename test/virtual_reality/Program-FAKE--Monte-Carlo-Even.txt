The term Monte Carlo method indicates any computer-aided procedure for numerical estimation that combines mathematical calculations with randomly generated numerical input values. Today it is an important tool in high energy physics while physicists and philosophers also often consider it a sort of virtual experiment. The Monte Carlo method was developed in the 1940s, in the context of U.S. American nuclear weapons research, an event often regarded as the origin of both computer simulation and "artificial reality" (Galison 1997). The present paper interrogates this strong claim by focusing on the emergence of Monte Carlo event generators in particle physics in the early 1960s. This historical case study shows how, as Monte Carlo computation became part of the toolbox of particle physicists around 1960, it was neither usually referred to as a "computer simulation" nor was it regarded as a surrogate for experimentation. In revising the history of this method, this paper asks, in what context did particle physicists of the 1960s decide to create FAKE, the first high-energy-physics Monte Carlo event simulator? What was their goal? And what epistemic role did FAKE play? In answering these questions, it is argued that Monte Carlo computations were not introduced into particle physics to simulate experiments, but rather they played the role of theoretical tools. The Monte Carlo method was able to do this thanks to its random component, a property which provided a means of modeling a specific phenomenon, so-called "(particle) resonances". Indeed, in doing so, event generators even came to mutually assimilate and reshape the notions of particle and resonance, taking up an epistemic function which had previously been confined to physical-mathematical formulae: that of a medium which could express aspects of particle theory.

https://www.ncbi.nlm.nih.gov/pubmed/31628493