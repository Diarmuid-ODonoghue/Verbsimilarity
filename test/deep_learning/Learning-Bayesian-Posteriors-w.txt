We seek to achieve the holy grail of Bayesian inference for gravitational-wave astronomy: using deep-learning techniques to instantly produce the posterior p(θ|D) for the source parameters θ, given the detector data D. To do so, we train a deep neural network to take as input a signal + noise dataset (drawn from the astrophysical source-parameter prior and the sampling distribution of detector noise), and to output a parametrized approximation of the corresponding posterior. We rely on a compact representation of the data based on reduced-order modeling, which we generate efficiently using a separate neural-network waveform interpolant [A. J. K. Chua, C. R. Galley, and M. Vallisneri, Phys. Rev. Lett. 122, 211101 (2019)PRLTAO0031-900710.1103/PhysRevLett.122.211101]. Our scheme has broad relevance to gravitational-wave applications such as low-latency parameter estimation and characterizing the science returns of future experiments.

https://www.ncbi.nlm.nih.gov/pubmed/32058738